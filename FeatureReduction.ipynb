{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $exclude.`org.slf4j:slf4j-log4j12`, $ivy.`org.slf4j:slf4j-nop:1.7.21` // for cleaner logs\n",
    "//import $profile.`hadoop-2.6`\n",
    "import $ivy.`org.apache.spark::spark-sql:2.1.0` // adjust spark version - spark >= 2.0\n",
    "//import $ivy.`org.apache.hadoop:hadoop-aws:2.6.4`\n",
    "import $ivy.`org.jupyter-scala::spark:0.4.2` // for JupyterSparkSession (SparkSession aware of the jupyter-scala kernel)\n",
    "\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql._\n",
    "import jupyter.spark.session._\n",
    "import Resolvers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.vegas-viz::vegas:0.3.9`\n",
    "import vegas._\n",
    "import vegas.data.External._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interp.resolvers() = interp.resolvers() :+ Resolver.Http(\n",
    "  \"isarn project\",\n",
    "  \"https://dl.bintray.com/isarn/maven/\",\n",
    "  MavenPattern,\n",
    "  true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.isarnproject::isarn-sketches:0.0.3.rc1` // \"org.isarnproject\" %% \"isarn-sketches\" % \"0.0.2\"\n",
    "import org.isarnproject.sketches._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val sparkSession = JupyterSparkSession.builder() // important - call this rather than SparkSession.builder()\n",
    "  .jupyter() // this method must be called straightaway after builder()\n",
    "  .master(\"spark://frclust:7077\")\n",
    "  .appName(\"notebook\")\n",
    "  .getOrCreate()\n",
    "val sc = sparkSession.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit class TDEnhance(td: TDigest) {\n",
    "  def toVegasXY: Seq[(Double, Double)] = {\n",
    "    val q = (0.001 +: (0.05 to 0.95 by 0.05) :+ 0.999).toVector\n",
    "    q.map(q => (td.cdfInverse(q), q))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val raw = sc.parallelize(Vector.fill(1000000) { scala.util.Random.nextGaussian() }, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val td = raw.aggregate(TDigest.empty())(\n",
    "    (td, x) => td + x,\n",
    "    (td1, td2) => td1 ++ td2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Vegas(\"CDF\")\n",
    "    .withXY(td.toVegasXY)\n",
    "    .encodeX(\"x\", Quant)\n",
    "    .encodeY(\"y\", Quant)\n",
    "    .mark(Line)\n",
    "    .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val trdd = sc.textFile(\"/data/tox21/tox21_dense_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trdd.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
