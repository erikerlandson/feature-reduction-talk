{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$exclude.$                        , $ivy.$                            // for cleaner logs\n",
       "//import $profile.`hadoop-2.6`\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   // adjust spark version - spark >= 2.0\n",
       "//import $ivy.`org.apache.hadoop:hadoop-aws:2.6.4`\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                // for JupyterSparkSession (SparkSession aware of the jupyter-scala kernel)\n",
       "\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mjupyter.spark.session._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mResolvers._\u001b[39m"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $exclude.`org.slf4j:slf4j-log4j12`, $ivy.`org.slf4j:slf4j-nop:1.7.21` // for cleaner logs\n",
    "//import $profile.`hadoop-2.6`\n",
    "import $ivy.`org.apache.spark::spark-sql:2.1.0` // adjust spark version - spark >= 2.0\n",
    "//import $ivy.`org.apache.hadoop:hadoop-aws:2.6.4`\n",
    "import $ivy.`org.jupyter-scala::spark:0.4.2` // for JupyterSparkSession (SparkSession aware of the jupyter-scala kernel)\n",
    "\n",
    "import org.apache.spark._\n",
    "import org.apache.spark.sql._\n",
    "import jupyter.spark.session._\n",
    "import Resolvers._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                           \n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mvegas._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mvegas.data.External._\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.vegas-viz::vegas:0.3.9`\n",
    "import vegas._\n",
    "import vegas.data.External._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "interp.resolvers() = interp.resolvers() :+ Resolver.Http(\n",
    "  \"isarn project\",\n",
    "  \"https://dl.bintray.com/isarn/maven/\",\n",
    "  MavenPattern,\n",
    "  true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                            // \"org.isarnproject\" %% \"isarn-sketches\" % \"0.0.2\"\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.isarnproject.sketches._\u001b[39m"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`org.isarnproject::isarn-sketches:0.0.3.rc1` // \"org.isarnproject\" %% \"isarn-sketches\" % \"0.0.2\"\n",
    "import org.isarnproject.sketches._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "// resolvers += \"Will's bintray\" at \"https://dl.bintray.com/willb/maven/\"\n",
    "interp.resolvers() = interp.resolvers() :+ Resolver.Http(\n",
    "  \"Will Benton\",\n",
    "  \"https://dl.bintray.com/willb/maven/\",\n",
    "  MavenPattern,\n",
    "  true\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                            // \"com.redhat.et\" %% \"silex\" % \"0.1.2\"\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import $ivy.`com.redhat.et::silex:0.1.2` // \"com.redhat.et\" %% \"silex\" % \"0.1.2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mTDEnhance\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit class TDEnhance(td: TDigest) extends Serializable {\n",
    "  def toXY: Vector[(Double, Double)] = {\n",
    "    val q = (0.001 +: (0.05 to 0.95 by 0.05) :+ 0.999).toVector\n",
    "    q.map(q => (td.cdfInverse(q), q))\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (io.netty.util.internal.logging.InternalLoggerFactory).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@6aa9fd5"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val spark = JupyterSparkSession.builder() // important - call this rather than SparkSession.builder()\n",
    "  .jupyter() // this method must be called straightaway after builder()\n",
    "  .master(\"spark://frclust:7077\")\n",
    "  .appName(\"notebook\")\n",
    "  .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mraw\u001b[39m: \u001b[32mrdd\u001b[39m.\u001b[32mRDD\u001b[39m[\u001b[32mDouble\u001b[39m] = ParallelCollectionRDD[0] at parallelize at cmd8.sc:1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val raw = spark.sparkContext.parallelize(Vector.fill(1000000) { scala.util.Random.nextGaussian() }, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mtd\u001b[39m: \u001b[32mTDigest\u001b[39m = \u001b[33mTDigest\u001b[39m(\n",
       "  \u001b[32m0.5\u001b[39m,\n",
       "  \u001b[32m0\u001b[39m,\n",
       "  \u001b[32m130\u001b[39m,\n",
       "  \u001b[33mMap\u001b[39m(\n",
       "    \u001b[32m-4.959149950003164\u001b[39m -> \u001b[32m1.0\u001b[39m,\n",
       "    \u001b[32m-4.928285167234059\u001b[39m -> \u001b[32m1.0\u001b[39m,\n",
       "    \u001b[32m-4.687110813092061\u001b[39m -> \u001b[32m1.0\u001b[39m,\n",
       "    \u001b[32m-4.519529976083678\u001b[39m -> \u001b[32m1.0\u001b[39m,\n",
       "    \u001b[32m-4.488087680479495\u001b[39m -> \u001b[32m2.2499937497163285\u001b[39m,\n",
       "    \u001b[32m-4.418217215431766\u001b[39m -> \u001b[32m1.7500062502836715\u001b[39m,\n",
       "    \u001b[32m-4.321959648009469\u001b[39m -> \u001b[32m3.2499843739076613\u001b[39m,\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val td = raw.aggregate(TDigest.empty())(\n",
    "    (td, x) => td + x,\n",
    "    (td1, td2) => td1 ++ td2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <iframe id=\"frame-vegas-abf1ad99-0927-4999-8f55-77ab056bda69\" sandbox=\"allow-scripts allow-same-origin\" style=\"border: none; width: 100%\" srcdoc=\"&lt;html&gt;\n",
       "  &lt;head&gt;\n",
       "    &lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/d3/3.5.17/d3.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega/2.6.3/vega.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://cdn.jsdelivr.net/webjars/org.webjars.bower/vega-lite/1.2.0/vega-lite.min.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "&lt;script src=&quot;https://vega.github.io/vega-editor/vendor/vega-embed.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;\n",
       "  &lt;/head&gt;\n",
       "  &lt;body&gt;\n",
       " &lt;script&gt;\n",
       "   var embedSpec = {\n",
       "     mode: &quot;vega-lite&quot;,\n",
       "     spec: {\n",
       "  &quot;mark&quot; : &quot;line&quot;,\n",
       "  &quot;encoding&quot; : {\n",
       "    &quot;x&quot; : {\n",
       "      &quot;field&quot; : &quot;x&quot;,\n",
       "      &quot;type&quot; : &quot;quantitative&quot;\n",
       "    },\n",
       "    &quot;y&quot; : {\n",
       "      &quot;field&quot; : &quot;y&quot;,\n",
       "      &quot;type&quot; : &quot;quantitative&quot;\n",
       "    }\n",
       "  },\n",
       "  &quot;description&quot; : &quot;CDF&quot;,\n",
       "  &quot;data&quot; : {\n",
       "    &quot;values&quot; : [\n",
       "      {\n",
       "        &quot;x&quot; : -3.0867475368339243,\n",
       "        &quot;y&quot; : 0.001\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : -1.6445700990789718,\n",
       "        &quot;y&quot; : 0.05\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : -1.280917618991889,\n",
       "        &quot;y&quot; : 0.1\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : -1.0346256913669265,\n",
       "        &quot;y&quot; : 0.15000000000000002\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : -0.8446839992229473,\n",
       "        &quot;y&quot; : 0.2\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : -0.6723399212383465,\n",
       "        &quot;y&quot; : 0.25\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : -0.5222276335171905,\n",
       "        &quot;y&quot; : 0.3\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : -0.38829308833039966,\n",
       "        &quot;y&quot; : 0.35\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : -0.25325122408153844,\n",
       "        &quot;y&quot; : 0.39999999999999997\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : -0.12546984561380556,\n",
       "        &quot;y&quot; : 0.44999999999999996\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : -8.516398218861576E-4,\n",
       "        &quot;y&quot; : 0.49999999999999994\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : 0.12621448869147353,\n",
       "        &quot;y&quot; : 0.5499999999999999\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : 0.2498253574955365,\n",
       "        &quot;y&quot; : 0.6\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : 0.3862012968651949,\n",
       "        &quot;y&quot; : 0.65\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : 0.5236278444610937,\n",
       "        &quot;y&quot; : 0.7000000000000001\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : 0.6733718758821806,\n",
       "        &quot;y&quot; : 0.7500000000000001\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : 0.842045342601325,\n",
       "        &quot;y&quot; : 0.8000000000000002\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : 1.0352029482527205,\n",
       "        &quot;y&quot; : 0.8500000000000002\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : 1.2884162955547231,\n",
       "        &quot;y&quot; : 0.9000000000000002\n",
       "      },\n",
       "      {\n",
       "        &quot;x&quot; : 3.1066115567655466,\n",
       "        &quot;y&quot; : 0.999\n",
       "      }\n",
       "    ]\n",
       "  }\n",
       "}\n",
       "   }\n",
       "   vg.embed(&quot;#vegas-abf1ad99-0927-4999-8f55-77ab056bda69&quot;, embedSpec, function(error, result) {});\n",
       " &lt;/script&gt;\n",
       " &lt;div id='vegas-abf1ad99-0927-4999-8f55-77ab056bda69'&gt;&lt;/div&gt;\n",
       "    &lt;/body&gt;\n",
       "&lt;/html&gt;\"></iframe>\n",
       "  <script>\n",
       "    if (typeof resizeIFrame != 'function') {\n",
       "      function resizeIFrame(el, k) {\n",
       "        $(el.contentWindow.document).ready(function() {\n",
       "          el.style.height = el.contentWindow.document.body.scrollHeight + 'px';\n",
       "        });\n",
       "        if (k <= 10) { setTimeout(function() { resizeIFrame(el, k+1) }, 1000 + (k * 250)) };\n",
       "      }\n",
       "    }\n",
       "    $().ready( function() { resizeIFrame($('#frame-vegas-abf1ad99-0927-4999-8f55-77ab056bda69').get(0), 1); });\n",
       "  </script>\n",
       "    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Vegas(\"CDF\")\n",
    "    .withXY(td.toXY)\n",
    "    .encodeX(\"x\", Quant)\n",
    "    .encodeY(\"y\", Quant)\n",
    "    .mark(Line)\n",
    "    .show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainCSV\u001b[39m: \u001b[32mDataFrame\u001b[39m = [_c0: string, AW: string ... 800 more fields]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainCSV = spark.read\n",
    "  .format(\"com.databricks.spark.csv\")\n",
    "  .option(\"header\", \"true\")\n",
    "  .option(\"mode\", \"DROPMALFORMED\")\n",
    "  .load(\"/data/tox21/tox21_dense_train_orig.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres12\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"_c0\"\u001b[39m,\n",
       "  \u001b[32m\"AW\"\u001b[39m,\n",
       "  \u001b[32m\"AWeight\"\u001b[39m,\n",
       "  \u001b[32m\"Arto\"\u001b[39m,\n",
       "  \u001b[32m\"BertzCT\"\u001b[39m,\n",
       "  \u001b[32m\"Chi0\"\u001b[39m,\n",
       "  \u001b[32m\"Chi1\"\u001b[39m,\n",
       "  \u001b[32m\"Chi10\"\u001b[39m,\n",
       "  \u001b[32m\"Chi2\"\u001b[39m,\n",
       "  \u001b[32m\"Chi3\"\u001b[39m,\n",
       "  \u001b[32m\"Chi3c\"\u001b[39m,\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainCSV.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainFV\u001b[39m: \u001b[32mrdd\u001b[39m.\u001b[32mRDD\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mDouble\u001b[39m]] = MapPartitionsRDD[12] at map at cmd13.sc:1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainFV = trainCSV.rdd.map(_.toSeq.toVector.drop(1).map(_.asInstanceOf[String].toDouble)).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.rdd.RDD\n",
       "\u001b[39m\n",
       "defined \u001b[32mfunction\u001b[39m \u001b[36mtdSketchFV\u001b[39m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.apache.spark.rdd.RDD\n",
    "def tdSketchFV(fv: RDD[Vector[Double]]): Vector[TDigest] = {\n",
    "    val tds = fv.aggregate(Array.empty[TDigest])(\n",
    "        (tdv, xv) => {\n",
    "            if (tdv.isEmpty) {\n",
    "                Array.tabulate(xv.length) { j => TDigest.empty(maxDiscrete=50) + xv(j) }\n",
    "            } else {\n",
    "                for { j <- 0 until xv.length } { tdv(j) += xv(j) }\n",
    "                tdv\n",
    "            }\n",
    "        },\n",
    "        (tdv1, tdv2) => {\n",
    "            if (tdv1.isEmpty) tdv2 else {\n",
    "                for { j <- 0 until tdv1.length } { tdv1(j) ++= tdv2(j) }\n",
    "                tdv1\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    tds.toVector\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36msynthesize\u001b[39m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def synthesize(tdVec: Vector[TDigest], n: Int, partitions: Int = 2) = {\n",
    "    implicit class AddSampling(td: TDigest) {\n",
    "        import org.isarnproject.collections.mixmaps.nearest.Cover\n",
    "        def cdfDiscreteInverse(q: Double): Double = {\n",
    "            td.clusters.mCover(q * td.clusters.sum).map(n => (n.data.key, n.data.value)) match {\n",
    "                case Cover(_, Some((x, _))) => x\n",
    "                case Cover(Some((x, _)), None) => x\n",
    "            }\n",
    "        }\n",
    "\n",
    "        def sample: Double = {\n",
    "            val clust = td.clusters\n",
    "            td.nclusters match {\n",
    "                case 0 => 0.0\n",
    "                case 1 => clust(clust.keyMin.get)\n",
    "                case n if (n <= td.maxDiscrete) => cdfDiscreteInverse(scala.util.Random.nextDouble)\n",
    "                case _ => td.cdfInverse(scala.util.Random.nextDouble)\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    val tdVecBC = spark.sparkContext.broadcast(tdVec)\n",
    "    spark.sparkContext.parallelize(1 to n, partitions).map { r => tdVecBC.value.map(_.sample) }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mfvSketches\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mTDigest\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[33mTDigest\u001b[39m(\n",
       "    \u001b[32m0.5\u001b[39m,\n",
       "    \u001b[32m50\u001b[39m,\n",
       "    \u001b[32m73\u001b[39m,\n",
       "    \u001b[33mMap\u001b[39m(\n",
       "      \u001b[32m1.0\u001b[39m -> \u001b[32m9.0\u001b[39m,\n",
       "      \u001b[32m1.333\u001b[39m -> \u001b[32m24.0\u001b[39m,\n",
       "      \u001b[32m1.5\u001b[39m -> \u001b[32m45.0\u001b[39m,\n",
       "      \u001b[32m1.6005818102304021\u001b[39m -> \u001b[32m27.96595892722711\u001b[39m,\n",
       "      \u001b[32m1.6650152196813153\u001b[39m -> \u001b[32m46.98490058907061\u001b[39m,\n",
       "      \u001b[32m1.7264260948678518\u001b[39m -> \u001b[32m30.04914048370228\u001b[39m,\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val fvSketches = tdSketchFV(trainFV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spark.sparkContext.broadcast(tdVec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36msynthFV\u001b[39m: \u001b[32mRDD\u001b[39m[\u001b[32mVector\u001b[39m[\u001b[32mDouble\u001b[39m]] = MapPartitionsRDD[229] at map at cmd15.sc:22"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val synthFV = synthesize(fvSketches, 48000, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mcom.redhat.et.silex.util.vectors.implicits._\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.mllib.tree.RandomForest\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.mllib.regression.LabeledPoint\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mcom.redhat.et.silex.cluster.ClusteringTreeModel\n",
       "\u001b[39m\n",
       "\u001b[32mimport \u001b[39m\u001b[36mClusteringTreeModel._\u001b[39m"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import com.redhat.et.silex.util.vectors.implicits._\n",
    "import org.apache.spark.mllib.tree.RandomForest\n",
    "import org.apache.spark.mllib.evaluation.BinaryClassificationMetrics\n",
    "import org.apache.spark.mllib.regression.LabeledPoint\n",
    "import com.redhat.et.silex.cluster.ClusteringTreeModel\n",
    "import ClusteringTreeModel._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainLab\u001b[39m: \u001b[32mRDD\u001b[39m[\u001b[32mLabeledPoint\u001b[39m] = MapPartitionsRDD[230] at map at cmd54.sc:1\n",
       "\u001b[36msynthLab\u001b[39m: \u001b[32mRDD\u001b[39m[\u001b[32mLabeledPoint\u001b[39m] = MapPartitionsRDD[231] at map at cmd54.sc:2\n",
       "\u001b[36mtrainFR\u001b[39m: \u001b[32mRDD\u001b[39m[\u001b[32mLabeledPoint\u001b[39m] = UnionRDD[232] at $plus$plus at cmd54.sc:3"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainLab = trainFV.map(_.toLabeledPoint(1.0))\n",
    "val synthLab = synthFV.map(_.toLabeledPoint(0.0))\n",
    "val trainFR = (trainLab ++ synthLab).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mwork\u001b[39m"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def work = {\n",
    "val rfFR = RandomForest.trainClassifier(\n",
    "    trainFR,              // training data\n",
    "    2,                    // number of classes\n",
    "    Map.empty[Int, Int],  // category info\n",
    "    100,                  // forest size\n",
    "    \"auto\",               // \n",
    "    \"gini\",               // split quality measure\n",
    "    10,                   // max depth\n",
    "    20,                   // max bins\n",
    "    235711)               // random seed\n",
    "val predictionAndLabels = trainLab.map { case LabeledPoint(label, features) =>\n",
    "  val prediction = rfFR.predict(features)\n",
    "  (prediction, label)\n",
    "}\n",
    "val metrics = new BinaryClassificationMetrics(predictionAndLabels)\n",
    "val incorrect = predictionAndLabels.filter { case (p, t) => p != t }\n",
    "println(s\"incorrect = ${incorrect.count}\")\n",
    "(rfFR, metrics)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incorrect = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mrfFR\u001b[39m: \u001b[32morg\u001b[39m.\u001b[32mapache\u001b[39m.\u001b[32mspark\u001b[39m.\u001b[32mmllib\u001b[39m.\u001b[32mtree\u001b[39m.\u001b[32mmodel\u001b[39m.\u001b[32mRandomForestModel\u001b[39m = TreeEnsembleModel classifier with 100 trees\n",
       "\n",
       "\u001b[36mmetrics\u001b[39m: \u001b[32mBinaryClassificationMetrics\u001b[39m = org.apache.spark.mllib.evaluation.BinaryClassificationMetrics@5e975368"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val (rfFR, metrics) = work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mrules\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mMap\u001b[39m[\u001b[32mDouble\u001b[39m, \u001b[32mSeq\u001b[39m[\u001b[32mSeq\u001b[39m[\u001b[32mPredicate\u001b[39m]]]] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[33mMap\u001b[39m(\n",
       "    \u001b[32m1.0\u001b[39m -> \u001b[33mArrayBuffer\u001b[39m(\n",
       "      \u001b[33mList\u001b[39m((MRVSA2 <= 0.0)),\n",
       "      \u001b[33mList\u001b[39m((MRVSA2 > 0.0), (RDFM30 <= 0.0)),\n",
       "      \u001b[33mList\u001b[39m((MRVSA2 > 0.0), (RDFM30 > 0.0), (slogPVSA7 <= 0.0)),\n",
       "      \u001b[33mList\u001b[39m(\n",
       "        (MRVSA2 > 0.0),\n",
       "        (RDFM30 > 0.0),\n",
       "        (slogPVSA7 > 0.0),\n",
       "        (slogPVSA2 <= 0.0)\n",
       "      ),\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val rules = rfFR.trees.map(_.rules(trainCSV.columns.toVector.drop(1), Map.empty[Int, Int]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(MRVSA7,21)\n",
      "(RNCS,20)\n",
      "(VSAEstate2,18)\n",
      "(VSAEstate0,18)\n",
      "(VSAEstate3,17)\n",
      "(slogPVSA8,16)\n",
      "(slogPVSA6,16)\n",
      "(slogPVSA3,14)\n",
      "(RDFV30,13)\n",
      "(PEOEVSA4,12)\n",
      "(RDFM29,11)\n",
      "(RDFM30,11)\n",
      "(PEOEVSA11,11)\n",
      "(slogPVSA7,11)\n",
      "(Chi4c,10)\n",
      "(RDFU27,10)\n",
      "(MRVSA8,9)\n",
      "(slogPVSA9,9)\n",
      "(PEOEVSA3,9)\n",
      "(PEOEVSA2,8)\n",
      "(MRVSA3,8)\n",
      "(RDFM27,8)\n",
      "(PEOEVSA10,8)\n",
      "(PEOEVSA12,7)\n",
      "(Chiv4c,7)\n",
      "(EstateVSA6,7)\n",
      "(RDFE30,7)\n",
      "(slogPVSA0,6)\n",
      "(RDFV24,6)\n",
      "(RDFE26,6)\n",
      "(RDFE28,6)\n",
      "(RDFP30,6)\n",
      "(RDFE29,6)\n",
      "(RDFM24,6)\n",
      "(RDFU25,6)\n",
      "(slogPVSA11,5)\n",
      "(MRVSA2,5)\n",
      "(RDFP29,5)\n",
      "(RDFU30,5)\n",
      "(RDFV29,5)\n",
      "(RDFU29,5)\n",
      "(MRVSA5,4)\n",
      "(RDFP24,4)\n",
      "(EstateVSA8,4)\n",
      "(RDFM25,4)\n",
      "(RDFV27,4)\n",
      "(PEOEVSA1,4)\n",
      "(EstateVSA0,4)\n",
      "(Chiv5ch,4)\n",
      "(RDFV25,4)\n",
      "(PEOEVSA8,4)\n",
      "(Chi5ch,3)\n",
      "(RDFP27,3)\n",
      "(RDFU24,3)\n",
      "(RDFM28,3)\n",
      "(RDFP25,3)\n",
      "(EstateVSA2,3)\n",
      "(RDFE27,3)\n",
      "(RDFV28,3)\n",
      "(RDFU26,3)\n",
      "(PEOEVSA13,3)\n",
      "(EstateVSA4,3)\n",
      "(RDFM20,3)\n",
      "(RDFM22,2)\n",
      "(RDFU28,2)\n",
      "(GATSm8,2)\n",
      "(Chiv6ch,2)\n",
      "(J,2)\n",
      "(EstateVSA1,2)\n",
      "(EstateVSA5,2)\n",
      "(RDFV23,2)\n",
      "(L1v,2)\n",
      "(RDFV20,2)\n",
      "(RDFP26,2)\n",
      "(RDFP28,2)\n",
      "(slogPVSA2,2)\n",
      "(RDFU21,2)\n",
      "(RDFE25,2)\n",
      "(RDFE21,2)\n",
      "(EstateVSA9,2)\n",
      "(bcutv4,2)\n",
      "(Chi6ch,2)\n",
      "(GeDi,1)\n",
      "(P2m,1)\n",
      "(WNSA2,1)\n",
      "(PEOEVSA5,1)\n",
      "(Ve,1)\n",
      "(RDFM26,1)\n",
      "(SPAN,1)\n",
      "(RDFP19,1)\n",
      "(RDFM19,1)\n",
      "(bcutp12,1)\n",
      "(bcute2,1)\n",
      "(MoRSEU3,1)\n",
      "(MoRSEV26,1)\n",
      "(Chi0,1)\n",
      "(rygr,1)\n",
      "(RDFP21,1)\n",
      "(RDFM14,1)\n",
      "(FNSA2,1)\n",
      "(RDFE22,1)\n",
      "(Platt,1)\n",
      "(RDFU23,1)\n",
      "(MoRSEP5,1)\n",
      "(bcute7,1)\n",
      "(RDFE19,1)\n",
      "(MoRSEC22,1)\n",
      "(GATSe8,1)\n",
      "(RDFE17,1)\n",
      "(RDFM1,1)\n",
      "(MSA,1)\n",
      "(naro,1)\n",
      "(RDFE24,1)\n",
      "(RDFV21,1)\n",
      "(MoRSEM1,1)\n",
      "(RDFE3,1)\n",
      "(DPSA2,1)\n",
      "(MRVSA1,1)\n",
      "(slogPVSA4,1)\n",
      "(RDFM23,1)\n",
      "(Tv,1)\n",
      "(RDFC30,1)\n",
      "(RDFE18,1)\n",
      "(MATSm6,1)\n",
      "(EstateVSA7,1)\n",
      "(MoRSEC20,1)\n",
      "(RDFV26,1)\n",
      "(MATSp1,1)\n",
      "(RDFV22,1)\n",
      "(naccr,1)\n",
      "(L1m,1)\n",
      "(P2v,1)\n",
      "(MoRSEU4,1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mfeatPerTree\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mArray\u001b[39m(\n",
       "  \u001b[32m\"slogPVSA3\"\u001b[39m,\n",
       "  \u001b[32m\"RDFM30\"\u001b[39m,\n",
       "  \u001b[32m\"MRVSA2\"\u001b[39m,\n",
       "  \u001b[32m\"slogPVSA7\"\u001b[39m,\n",
       "  \u001b[32m\"RNCS\"\u001b[39m,\n",
       "  \u001b[32m\"slogPVSA2\"\u001b[39m,\n",
       "  \u001b[32m\"VSAEstate2\"\u001b[39m,\n",
       "  \u001b[32m\"RDFU28\"\u001b[39m,\n",
       "  \u001b[32m\"Ve\"\u001b[39m,\n",
       "  \u001b[32m\"Chi4c\"\u001b[39m,\n",
       "  \u001b[32m\"RDFM30\"\u001b[39m,\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mfeatCounts\u001b[39m: \u001b[32mMap\u001b[39m[\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m] = \u001b[33mMap\u001b[39m(\n",
       "  \u001b[32m\"MRVSA8\"\u001b[39m -> \u001b[32m9\u001b[39m,\n",
       "  \u001b[32m\"PEOEVSA12\"\u001b[39m -> \u001b[32m7\u001b[39m,\n",
       "  \u001b[32m\"VSAEstate2\"\u001b[39m -> \u001b[32m18\u001b[39m,\n",
       "  \u001b[32m\"MRVSA5\"\u001b[39m -> \u001b[32m4\u001b[39m,\n",
       "  \u001b[32m\"Chi5ch\"\u001b[39m -> \u001b[32m3\u001b[39m,\n",
       "  \u001b[32m\"RDFM29\"\u001b[39m -> \u001b[32m11\u001b[39m,\n",
       "  \u001b[32m\"RDFP27\"\u001b[39m -> \u001b[32m3\u001b[39m,\n",
       "  \u001b[32m\"GeDi\"\u001b[39m -> \u001b[32m1\u001b[39m,\n",
       "  \u001b[32m\"P2m\"\u001b[39m -> \u001b[32m1\u001b[39m,\n",
       "  \u001b[32m\"RDFP24\"\u001b[39m -> \u001b[32m4\u001b[39m,\n",
       "  \u001b[32m\"slogPVSA3\"\u001b[39m -> \u001b[32m14\u001b[39m,\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mfeatHist\u001b[39m: \u001b[32mVector\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)] = \u001b[33mVector\u001b[39m(\n",
       "  (\u001b[32m\"MRVSA7\"\u001b[39m, \u001b[32m21\u001b[39m),\n",
       "  (\u001b[32m\"RNCS\"\u001b[39m, \u001b[32m20\u001b[39m),\n",
       "  (\u001b[32m\"VSAEstate2\"\u001b[39m, \u001b[32m18\u001b[39m),\n",
       "  (\u001b[32m\"VSAEstate0\"\u001b[39m, \u001b[32m18\u001b[39m),\n",
       "  (\u001b[32m\"VSAEstate3\"\u001b[39m, \u001b[32m17\u001b[39m),\n",
       "  (\u001b[32m\"slogPVSA8\"\u001b[39m, \u001b[32m16\u001b[39m),\n",
       "  (\u001b[32m\"slogPVSA6\"\u001b[39m, \u001b[32m16\u001b[39m),\n",
       "  (\u001b[32m\"slogPVSA3\"\u001b[39m, \u001b[32m14\u001b[39m),\n",
       "  (\u001b[32m\"RDFV30\"\u001b[39m, \u001b[32m13\u001b[39m),\n",
       "  (\u001b[32m\"PEOEVSA4\"\u001b[39m, \u001b[32m12\u001b[39m),\n",
       "  (\u001b[32m\"RDFM29\"\u001b[39m, \u001b[32m11\u001b[39m),\n",
       "\u001b[33m...\u001b[39m\n",
       "\u001b[36mfeatSelect\u001b[39m: \u001b[32mVector\u001b[39m[\u001b[32mString\u001b[39m] = \u001b[33mVector\u001b[39m(\n",
       "  \u001b[32m\"MRVSA7\"\u001b[39m,\n",
       "  \u001b[32m\"RNCS\"\u001b[39m,\n",
       "  \u001b[32m\"VSAEstate2\"\u001b[39m,\n",
       "  \u001b[32m\"VSAEstate0\"\u001b[39m,\n",
       "  \u001b[32m\"VSAEstate3\"\u001b[39m,\n",
       "  \u001b[32m\"slogPVSA8\"\u001b[39m,\n",
       "  \u001b[32m\"slogPVSA6\"\u001b[39m,\n",
       "  \u001b[32m\"slogPVSA3\"\u001b[39m,\n",
       "  \u001b[32m\"RDFV30\"\u001b[39m,\n",
       "  \u001b[32m\"PEOEVSA4\"\u001b[39m,\n",
       "  \u001b[32m\"RDFM29\"\u001b[39m,\n",
       "\u001b[33m...\u001b[39m"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val featPerTree = for {\n",
    "    rmap <- rules\n",
    "    feats = {\n",
    "        val fraw = for {\n",
    "            vrules <- rmap.values\n",
    "            plist <- vrules\n",
    "            pred <- plist\n",
    "        } yield { pred.feature }\n",
    "        fraw.toSet.toSeq\n",
    "    }\n",
    "    f <- feats\n",
    "} yield { f }\n",
    "val featCounts = featPerTree.foldLeft(Map.empty[String, Int])((m, f) => m + (f -> (1 + m.getOrElse(f, 0))))\n",
    "val featHist = featCounts.toSeq.sortBy { case (_, n) => -n}.toVector\n",
    "val featSelect = featHist.filter { case (_, n) => n > 1 }.map { case (f, _) => f }\n",
    "println(featHist.mkString(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres82\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m82\u001b[39m"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "featSelect.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mtrainCSVFR\u001b[39m: \u001b[32mDataFrame\u001b[39m = [MRVSA7: string, RNCS: string ... 80 more fields]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val trainCSVFR = trainCSV.select(featSelect.head, featSelect.tail :_*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----+----------+----------+----------+---------+---------+---------+------+--------+------+------+---------+---------+-----+------+------+---------+--------+--------+------+------+---------+---------+------+----------+------+---------+------+-------+------+------+------+------+-------+----------+------+------+------+------+------+------+------+----------+------+------+--------+----------+-------+------+--------+------+------+-------+------+------+----------+------+------+-------+---------+----------+------+------+------+------+-------+-----+----------+----------+------+------+------+------+------+---------+-------+-------+-------+----------+------+------+\n",
      "|MRVSA7|RNCS|VSAEstate2|VSAEstate0|VSAEstate3|slogPVSA8|slogPVSA6|slogPVSA3|RDFV30|PEOEVSA4|RDFM29|RDFM30|PEOEVSA11|slogPVSA7|Chi4c|RDFU27|MRVSA8|slogPVSA9|PEOEVSA3|PEOEVSA2|MRVSA3|RDFM27|PEOEVSA10|PEOEVSA12|Chiv4c|EstateVSA6|RDFE30|slogPVSA0|RDFV24| RDFE26|RDFE28|RDFP30|RDFE29|RDFM24| RDFU25|slogPVSA11|MRVSA2|RDFP29|RDFU30|RDFV29|RDFU29|MRVSA5|RDFP24|EstateVSA8|RDFM25|RDFV27|PEOEVSA1|EstateVSA0|Chiv5ch|RDFV25|PEOEVSA8|Chi5ch|RDFP27| RDFU24|RDFM28|RDFP25|EstateVSA2|RDFE27|RDFV28| RDFU26|PEOEVSA13|EstateVSA4|RDFM20|RDFM22|RDFU28|GATSm8|Chiv6ch|    J|EstateVSA1|EstateVSA5|RDFV23|   L1v|RDFV20|RDFP26|RDFP28|slogPVSA2| RDFU21| RDFE25| RDFE21|EstateVSA9|bcutv4|Chi6ch|\n",
      "+------+----+----------+----------+----------+---------+---------+---------+------+--------+------+------+---------+---------+-----+------+------+---------+--------+--------+------+------+---------+---------+------+----------+------+---------+------+-------+------+------+------+------+-------+----------+------+------+------+------+------+------+------+----------+------+------+--------+----------+-------+------+--------+------+------+-------+------+------+----------+------+------+-------+---------+----------+------+------+------+------+-------+-----+----------+----------+------+------+------+------+------+---------+-------+-------+-------+----------+------+------+\n",
      "|     0|   0|         0|         0|         0|        0|        0|        0|     0|       0|     0|     0|   11.033|   43.612|    0|     0|     0|    22.75|   4.567|   4.984| 7.048|     0|        0|        0|     0|    79.844|     0|   39.909|     0|      0|     0|     0|     0|     0|      0|         0| 4.984|     0|     0|     0|     0|22.935|     0|    22.935|     0|     0|       0|         0|      0|     0|  11.033|     0|     0|      0|     0|     0|         0|     0|     0|      0|        0|    10.772| 0.444| 0.006|     0| 0.082|  0.128|    0|    12.407|         0| 0.008| 8.412| 1.711|     0|     0|    7.048|  3.679|      0|  3.968|         0| 3.681| 0.373|\n",
      "|     0|   0|         0|         0|         0|        0|        0|        0|     0|       0|     0|     0|    5.429|    33.42|    0|     0|  28.2|        0|       0|       0|     0|     0|     5.76|        0|     0|         0|     0|   74.756|     0|      0|     0|     0|     0|     0|      0|     63.72|     0|     0|     0|     0|     0|     0|     0|     4.417|     0|     0|   4.795|     5.969|      0|     0|  14.915|     0|     0|      0|     0|     0|    22.077|     0|     0|      0|   59.115|     6.066|13.427|     0|     0|  1.82|  0.077|    0|    105.09|    30.332|     0| 6.437| 0.635|     0|     0|        0|      0|      0|      0|    19.802| 3.151| 0.219|\n",
      "|     0|   0|         0|         0|         0|        0|        0|    29.59| 0.538|       0| 1.385| 0.114|        0|        0|0.762|14.627|     0|        0|       0|       0| 29.59| 2.839|   23.651|        0| 0.298|    34.619| 2.975|   11.257|13.898| 28.251|13.367|  0.75| 5.645|11.503| 41.673|         0| 6.151| 1.717| 3.279| 1.439|  5.65|28.439|16.265|    56.842| 5.659| 3.529|       0|   101.807|  0.166| 8.545|  72.242| 0.287| 4.213| 52.082| 1.348|10.806|    38.525|14.199| 2.533| 29.005|        0|     14.22|33.081|21.339|13.542| 0.945|   0.11|    0|    66.949|    28.067|18.389|15.198|37.518| 7.792| 3.199|   61.637| 92.782| 41.608| 90.349|    25.221| 3.626| 0.191|\n",
      "|     0|   0|         0|         0|         0|        0|        0|        0|     0|       0| 0.016|     0|        0|   11.146|    0| 4.236|     0|   11.375|       0|  28.329|     0| 0.417|   23.362|        0|     0|         0|     0|   20.013| 5.288| 12.168| 2.701|     0| 0.928| 2.835| 21.483|         0|     0| 0.149|     0| 0.096| 1.012|66.181| 6.766|    59.406| 0.948| 0.563|       0|    35.816|      0| 3.388|       0|     0| 0.776| 26.935| 0.083| 4.706|         0| 3.902| 0.288| 12.636|   23.877|    67.344|17.091|14.896| 2.799| 0.246|  0.175|    0|         0|         0|12.376|10.932|26.276| 2.643| 0.423|   28.767| 62.754| 19.453| 60.857|         0| 3.724| 0.537|\n",
      "|     0|   0|         0|         0|         0|        0|        0|   11.327|  7.28|       0| 9.168|   4.9|   59.072|   21.806|    0|82.255|  5.75|        0|       0|   4.984|11.652|24.404|     5.96|    5.969|     0|    38.113|26.769|   58.902|52.459|104.994|63.701| 8.773|43.354|50.336|124.685|         0|78.004|16.195|28.377|13.787|44.741|26.241|57.959|    21.044|41.016|29.277|  58.149|    114.21|  0.273|47.229|  18.628| 0.572|32.881|144.879|13.399|52.192|    63.577|81.112|18.751|104.669|        0|     41.69|90.329|64.449|65.636| 0.913|  0.083|    0|   100.318|    43.583|68.287|39.142|89.946|43.849|22.136|   78.423|202.823|124.635|205.709|    48.569| 3.731|  0.25|\n",
      "|     0|   0|         0|         0|         0|        0|        0|        0| 1.249|  11.762| 0.776| 0.293|        0|        0|    0|13.233|     0|        0|       0|       0|     0| 5.339|        0|        0|     0|    11.762| 5.875|    5.317| 4.859| 10.658| 8.452| 1.691| 9.136| 3.163|  6.952|    11.762| 5.317| 3.401| 6.425|  2.45| 9.763| 6.545| 5.617|         0| 0.362| 4.473|       0|     6.104|      0| 1.407|   6.104|     0|  6.03| 13.326| 3.796|  1.93|      5.25|12.374| 4.399| 11.327|        0|     43.42| 4.045| 4.915| 8.945| 0.713|  0.028|2.104|     6.042|         0| 3.887|24.584| 4.303| 4.524| 4.819|        0| 16.006|  6.383| 15.056|     5.107| 3.315| 0.083|\n",
      "|     0|   0|         0|         0|         0|        0|        0|   17.038|     0|       0|     0|     0|        0|        0|    0|     0|  5.75|    5.687|       0|       0|     0|     0|        0|        0|     0|     6.924|     0|    5.717|     0|      0|     0|     0|     0|     0|      0|         0|     0|     0|     0|     0|     0|     0|     0|     2.644|     0|     0|       0|    25.031|      0|     0|       0|     0|     0|      0|     0|     0|         0|     0|     0|      0|   81.842|         0|     0|     0|     0|     0|  0.021|2.011|    10.611|    12.133|     0| 4.556|     0|     0|     0|   25.031|      0|      0|      0|    10.114| 2.438| 0.056|\n",
      "|     0|   0|         0|         0|         0|        0|        0|        0|     0|       0|     0|     0|        0|        0|    0|     0|     0|        0|       0|       0|     0|     0|        0|        0|     0|         0|     0|        0|     0|      0|     0|     0|     0|     0|      0|    46.024|   9.8|     0|     0|     0|     0|26.179|     0|    24.436|     0|     0|       0|         0|      0|     0|       0|     0|     0|      0|     0|     0|         0|     0|     0|      0|        0|         0| 0.003|     0|     0|     0|      0|3.934|         0|    21.588|     0|10.242| 0.041|     0|     0|        0|  0.212|      0|  0.188|         0| 2.955|     0|\n",
      "|     0|   0|         0|         0|         0|        0|        0|    5.409|     0|  12.407|     0|     0|        0|   10.772|    0|     0|  5.75|        0|       0|       0|     0|     0|        0|        0|     0|         0|     0|    4.737| 0.004|      0|     0|     0|     0|     0|      0|    12.407|   4.9|     0|     0|     0|     0|19.696| 0.007|    10.146|     0|     0|   5.409|         0|      0|     0|   6.607|     0|     0|  0.046|     0|     0|     5.836|     0|     0|      0|        0|    19.262|  0.38| 0.036|     0| 0.033|  0.049|    0|    12.407|         0| 0.021|10.702| 1.514|     0|     0|        0|  7.077|      0|  6.388|         0| 3.343| 0.139|\n",
      "|     0|   0|         0|         0|         0|        0|        0|   11.735| 0.012|  24.814| 0.083| 0.013|        0|   11.033|0.102| 1.503|     0|     4.39|       0|  14.169| 5.918|   1.5|        0|        0| 0.059|    30.332| 0.129|        0| 2.905|  2.848| 3.057| 0.011| 0.322|  2.42|   6.47|    24.814|14.868| 0.095| 0.094| 0.078| 0.325|33.854| 3.295|     9.474| 1.887| 0.554|       0|     5.601|  0.028| 2.763|  11.033| 0.096| 0.509|  6.133| 1.628| 3.265|    19.262| 1.846| 0.652|  3.051|    5.969|    13.176| 7.223| 6.042|  2.72| 0.098|  0.088|    0|    55.043|     6.066|   2.7| 14.42| 8.558| 1.259| 0.662|    27.11| 10.874|  6.427|  11.05|     9.185| 3.425| 0.199|\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|     0|   0|         0|         0|         0|        0|        0|   33.473| 6.443|  24.814| 7.575| 4.083|        0|        0|    0| 37.44|     0|        0|       0|       0|11.836| 6.636|   23.838|        0|     0|         0|22.792|   31.901|11.169| 39.231|36.203| 7.728|38.495|11.936| 40.127|    24.814|31.901|12.874|23.923| 10.68|39.824|26.179|12.902|    21.637| 10.81|10.456|  32.271|         0|      0|11.427|       0|     0|12.624| 39.962|15.252|13.807|    24.925| 36.48|12.753| 40.842|        0|    38.525| 11.98|10.023|36.218| 0.047|      0|    0|    48.652|         0|14.238|37.616| 14.73| 14.24|14.886|        0| 46.607| 39.142| 45.736|         0| 3.363|     0|\n",
      "|     0|   0|         0|         0|         0|        0|        0|   11.634|     0|  12.407|     0|     0|        0|        0|    0|     0|11.499|    8.781|       0|   8.781|     0|     0|        0|        0|     0|         0|     0|   14.791| 0.079|  0.001|     0|     0|     0| 0.053|  0.013|    12.407| 5.317|     0|     0|     0|     0| 13.09| 0.112|     9.474| 0.002|     0|       0|    12.208|      0| 0.002|       0|     0|     0|  0.775|     0| 0.002|    37.182|     0|     0|  0.001|        0|    24.265| 6.802| 1.172|     0|   0.2|  0.107|    0|    49.339|    12.133| 0.828|13.027| 3.955|     0|     0|   12.842|  6.168|  0.018|  7.395|    18.994| 3.382| 0.272|\n",
      "|     0|   0|         0|         0|         0|        0|   10.045|    5.415|     0|       0|     0|     0|        0|        0|0.558|     0|  5.75|        0|       0|       0| 5.415|     0|        0|        0|  0.53|    18.199|     0|        0| 0.002|      0|     0|     0|     0| 0.005|  1.212|    23.202|     0|     0|     0|     0|     0|     0| 0.002|    23.202| 0.301|     0|       0|         0|      0| 0.362|       0|     0|     0|  0.002|     0| 0.572|    22.216|     0|     0|      0|        0|     5.563| 9.235| 0.281|     0| 1.647|  0.048|1.974|     10.83|    12.133| 0.218|13.052| 5.281|     0|     0|   11.836|  2.162|  1.445|  2.225|     5.107| 3.242| 0.136|\n",
      "|     0|   0|         0|         0|         0|        0|        0|    5.409|     0|       0|     0|     0|     5.96|   10.903|    0|     0|  5.75|        0|   5.101|   5.426| 5.101|     0|        0|        0|     0|    24.396|     0|   15.479| 0.092|      0|     0|     0|     0| 0.007|      0|         0|15.727|     0|     0|     0|     0|13.655| 0.149|    10.146|     0|     0|   5.409|         0|  0.036|     0|  13.324| 0.096|     0|   1.03|     0|     0|         0|     0|     0|      0|        0|    12.842|  0.32|  0.23|     0| 1.138|  0.024|1.601|      5.96|    13.324| 0.289|10.237| 0.997|     0|     0|        0|  2.102|      0|  1.924|         0| 3.193| 0.068|\n",
      "|     0|   0|         0|         0|         0|        0|   10.045|        0|     0|  11.601|     0|     0|        0|        0|    0|     0|     0|        0|       0|       0|     0|     0|    5.783|        0|     0|         0|     0|        0|     0|      0|     0|     0|     0|     0|      0|    34.803|     0|     0|     0|     0|     0|  5.88|     0|    34.803|     0|     0|   4.795|         0|      0|     0|  10.903|     0|     0|      0|     0|     0|    15.609|     0|     0|      0|        0|     6.066|     0|     0|     0|     0|  0.024|2.442|    11.663|    12.133|     0| 4.264|     0|     0|     0|        0|      0|      0|      0|     4.795| 2.578| 0.068|\n",
      "|     0|   0|         0|         0|         0|        0|        0|   28.584|     0|       0|     0|     0|        0|        0|0.388|     0|     0|        0|       0|   4.795|28.584|     0|     6.29|        0| 0.263|     6.924|     0|        0|     0|      0|     0|     0|     0|     0|      0|         0|     0|     0|     0|     0|     0|13.214|     0|    14.211|     0|     0|       0|    95.462|  0.114|     0|   47.64|  0.19|     0|      0|     0|     0|    19.262|     0|     0|      0|    5.969|        13|     0|     0|     0|  1.01|  0.144|1.267|    38.208|         0|     0|6.8105|     0|     0|     0|   19.005|      0|      0|      0|    45.647|  3.51| 0.163|\n",
      "|     0|   0|         0|         0|         0|        0|        0|        0| 0.884|       0| 0.137|  0.38|        0|        0|0.354| 9.204|     0|        0|       0|       0|     0| 4.718|        0|        0| 0.316|         0| 3.762|   16.981| 4.122|   9.52| 7.037| 1.229| 3.585| 3.145|  9.207|         0|     0| 0.845| 4.032| 0.593| 3.971|27.688| 4.732|         0|  0.58| 2.632|       0|         0|      0| 1.827|  27.688|     0| 3.603| 13.205| 1.198| 2.476|         0| 8.747| 2.225| 10.261|        0|    83.595|  3.39| 3.655| 7.422| 0.001|      0|    0|    16.981|         0|  2.92| 25.34| 4.866| 3.961| 2.691|        0| 14.294|  8.436| 13.536|         0| 3.252|     0|\n",
      "|     0|   0|         0|         0|         0|        0|        0|        0| 0.023|       0| 0.128| 0.003|        0|        0| 0.25| 5.921|  5.75|        0|       0|       0|     0| 0.362|        0|        0| 0.224|    30.332| 0.187|   21.718| 3.111|  6.129| 2.875| 0.035| 2.502| 2.014|   7.66|         0|     0|  0.73|  0.21| 0.541| 2.733|33.792| 3.683|     4.737| 1.406| 1.306|       0|         0|      0| 2.029|   20.64|     0| 1.703| 10.746| 0.862| 2.626|         0| 5.582| 1.106|  6.539|        0|    70.753| 3.152| 1.357| 3.111| 0.003|  0.032|    0|    16.981|         0| 3.221|18.319| 6.539| 2.627| 1.245|        0| 11.938|  7.227| 11.124|         0| 3.382| 0.102|\n",
      "|     0|   0|         0|         0|         0|        0|        0|        0| 3.461|       0| 6.916| 2.761|        0|        0|    0|11.803|     0|        0|       0|   4.567|     0| 1.536|   12.394|        0|     0|         0| 7.075|   21.549| 4.672|  8.152|  6.95| 4.067|10.786| 4.482|  12.09|         0|     0| 4.919| 7.246| 3.829|11.108|     0| 5.084|         0| 1.146| 3.172|       0|         0|      0| 2.948|       0|     0| 3.937| 11.441| 2.089| 3.835|         0|10.914| 2.612|  8.318|        0|    96.436|11.223| 2.877| 7.527| 0.001|  0.029|    0|    16.981|         0| 6.019|31.054| 7.905| 4.914| 2.936|    6.545| 15.393| 11.578| 14.182|         0| 3.368| 0.102|\n",
      "|     0|   0|         0|         0|         0|        0|        0|        0|     0|       0|     0|     0|        0|    5.573|    0|     0|     0|   11.375|       0|   4.576|     0|     0|    5.712|        0|     0|         0|     0|   22.207| 1.034|  0.321|     0|     0|     0| 0.173|  2.817|         0|     0|     0|     0|     0|     0|52.086| 1.521|         0|  0.02|     0|       0|         0|      0| 0.252|       0|     0|     0|  8.053|     0| 0.408|         0|     0|     0|  0.362|        0|     39.36| 8.225| 1.493|     0| 0.032|  0.083|    0|    12.407|         0| 2.032|10.497| 8.376| 0.052|     0|        0| 20.332|  2.499| 18.964|         0| 3.308|  0.25|\n",
      "+------+----+----------+----------+----------+---------+---------+---------+------+--------+------+------+---------+---------+-----+------+------+---------+--------+--------+------+------+---------+---------+------+----------+------+---------+------+-------+------+------+------+------+-------+----------+------+------+------+------+------+------+------+----------+------+------+--------+----------+-------+------+--------+------+------+-------+------+------+----------+------+------+-------+---------+----------+------+------+------+------+-------+-----+----------+----------+------+------+------+------+------+---------+-------+-------+-------+----------+------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trainCSVFR.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala211",
   "nbconvert_exporter": "script",
   "pygments_lexer": "scala",
   "version": "2.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
